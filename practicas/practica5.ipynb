{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5191ebc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install datasets\n",
    "# !pip install transformers\n",
    "# !pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3158a98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 8530\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 1066\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 1066\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "data = load_dataset(\"rotten_tomatoes\")\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3013841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['the rock is destined to be the 21st century\\'s new \" conan \" and that he\\'s going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .',\n",
       "  'things really get weird , though not particularly scary : the movie is all portent and no content .'],\n",
       " 'label': [1, 0]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"train\"][0, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6220077d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n",
      "MPS available: True\n",
      "MPS built: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.__version__)\n",
    "print(\"MPS available:\", torch.backends.mps.is_available())\n",
    "print(\"MPS built:\", torch.backends.mps.is_built())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "43b5ff39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "model_path = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "\n",
    "pipe = pipeline(\n",
    "    model=model_path,\n",
    "    tokenizer=model_path,\n",
    "    # return_all_scores=True,\n",
    "    top_k=None, # top_k=1 <=> return_all_scores=False\n",
    "    device=0 if torch.backends.mps.is_available() else -1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0222c678",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1066/1066 [00:27<00:00, 39.05it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from transformers.pipelines.pt_utils import KeyDataset\n",
    "\n",
    "# Run inference\n",
    "y_pred = []\n",
    "\n",
    "for output in tqdm(pipe(KeyDataset(data[\"test\"], \"text\")), total=len(data[\"test\"])):\n",
    "    # print(output)\n",
    "    positive_score, negative_score = 0, 0\n",
    "    for item in output:\n",
    "        if item[\"label\"] == \"positive\":\n",
    "            positive_score = item[\"score\"]\n",
    "        elif item[\"label\"] == \"negative\":\n",
    "            negative_score = item[\"score\"]\n",
    "    assignment = np.argmax([negative_score, positive_score])\n",
    "    y_pred.append(assignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2c56f7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = data[\"test\"][\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "34006d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Postive reviews: 533 / 1066 (50.00%)\n",
      "Postive reviews: 457 / 1066 (42.87%)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Postive reviews: {sum(y_true)} / {len(y_true)} ({100 * sum(y_true) / len(y_true):.2f}%)\")\n",
    "print(f\"Postive reviews: {sum(y_pred)} / {len(y_pred)} ({100 * sum(y_pred) / len(y_pred):.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "67fd922b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1062</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1065</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1066 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      y_true  y_pred\n",
       "0          1       1\n",
       "1          1       1\n",
       "2          1       0\n",
       "3          1       1\n",
       "4          1       1\n",
       "...      ...     ...\n",
       "1061       0       0\n",
       "1062       0       0\n",
       "1063       0       0\n",
       "1064       0       0\n",
       "1065       0       0\n",
       "\n",
       "[1066 rows x 2 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "report1 = pandas.DataFrame([y_true, y_pred], index=[\"y_true\", \"y_pred\"]).T\n",
    "report1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "37cf64b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual_1</th>\n",
       "      <th>actual_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pred_1</th>\n",
       "      <td>384</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred_0</th>\n",
       "      <td>149</td>\n",
       "      <td>460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        actual_1  actual_0\n",
       "pred_1       384        73\n",
       "pred_0       149       460"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TP = report1[(report1[\"y_true\"] == 1) & (report1[\"y_pred\"] == 1)].shape[0]\n",
    "FP = report1[(report1[\"y_true\"] == 0) & (report1[\"y_pred\"] == 1)].shape[0]\n",
    "TN = report1[(report1[\"y_true\"] == 0) & (report1[\"y_pred\"] == 0)].shape[0]\n",
    "FN = report1[(report1[\"y_true\"] == 1) & (report1[\"y_pred\"] == 0)].shape[0]\n",
    "\n",
    "pandas.DataFrame([\n",
    "    [TP, FP],\n",
    "    [FN, TN],\n",
    "], index=[\"pred_1\", \"pred_0\"], columns=[\"actual_1\", \"actual_0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f94600f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Negative Review</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.81</td>\n",
       "      <td>533.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive Review</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.78</td>\n",
       "      <td>533.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>1066.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>1066.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>1066.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 precision  recall  f1-score  support\n",
       "Negative Review       0.76    0.86      0.81    533.0\n",
       "Positive Review       0.84    0.72      0.78    533.0\n",
       "accuracy              0.79    0.79      0.79   1066.0\n",
       "macro avg             0.80    0.79      0.79   1066.0\n",
       "weighted avg          0.80    0.79      0.79   1066.0"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Positivo (1)\n",
    "TP_pos = TP\n",
    "FP_pos = FP\n",
    "TN_pos = TN\n",
    "FN_pos = FN\n",
    "\n",
    "precision_pos = TP_pos / (TP_pos + FP_pos)\n",
    "recall_pos    = TP_pos / (TP_pos + FN_pos)\n",
    "f1_pos        = 2 * precision_pos * recall_pos / (precision_pos + recall_pos)\n",
    "support_pos   = TP_pos + FN_pos\n",
    "\n",
    "# Negativo (0)\n",
    "TP_neg = TN\n",
    "FP_neg = FN\n",
    "TN_neg = TP\n",
    "FN_neg = FP\n",
    "\n",
    "precision_neg = TP_neg / (TP_neg + FP_neg)\n",
    "recall_neg    = TP_neg / (TP_neg + FN_neg)\n",
    "f1_neg        = 2 * precision_neg * recall_neg / (precision_neg + recall_neg)\n",
    "support_neg   = TP_neg + FN_neg\n",
    "\n",
    "# Accuracy\n",
    "accuracy = (TP_pos + TN_pos) / (TP_pos + TN_pos + FP_pos + FN_pos)\n",
    "\n",
    "# Macro average\n",
    "precision_macro = (precision_pos + precision_neg) / 2\n",
    "recall_macro    = (recall_pos + recall_neg) / 2\n",
    "f1_macro        = (f1_pos + f1_neg) / 2\n",
    "\n",
    "# Weighted average\n",
    "precision_weighted = (precision_pos * support_pos + precision_neg * support_neg) / (support_pos + support_neg)\n",
    "recall_weighted    = (recall_pos * support_pos + recall_neg * support_neg) / (support_pos + support_neg)\n",
    "f1_weighted        = (f1_pos * support_pos + f1_neg * support_neg) / (support_pos + support_neg)\n",
    "\n",
    "report2 = pandas.DataFrame({\n",
    "    \"precision\": [precision_neg, precision_pos],\n",
    "    \"recall\":    [recall_neg, recall_pos],\n",
    "    \"f1-score\":  [f1_neg, f1_pos],\n",
    "    \"support\":   [support_neg, support_pos]\n",
    "}, index=[\"Negative Review\", \"Positive Review\"])\n",
    "\n",
    "report2.loc[\"accuracy\"]     = [accuracy, accuracy, accuracy, support_neg + support_pos]\n",
    "report2.loc[\"macro avg\"]    = [precision_macro, recall_macro, f1_macro, support_neg + support_pos]\n",
    "report2.loc[\"weighted avg\"] = [precision_weighted, recall_weighted, f1_weighted, support_neg + support_pos]\n",
    "\n",
    "report2.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "acce1b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "Negative Review       0.76      0.86      0.81       533\n",
      "Positive Review       0.84      0.72      0.78       533\n",
      "\n",
      "       accuracy                           0.79      1066\n",
      "      macro avg       0.80      0.79      0.79      1066\n",
      "   weighted avg       0.80      0.79      0.79      1066\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=[\"Negative Review\", \"Positive Review\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
