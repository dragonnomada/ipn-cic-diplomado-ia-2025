{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dfbc656",
   "metadata": {},
   "source": [
    "## Clasificación de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eca8848a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dragonnomada/.pyenv/versions/3.10.15/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification\n",
    ")\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29172bac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4ab1e80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e4dd4883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50257"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7b20b418",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"gpt2\", num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f89efc68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[   40,   716,   523,  6507,    11,   314,   716, 34253]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(\"I am so sad, I am starving\", return_tensors=\"pt\")\n",
    "\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4deda402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutputWithPast(loss=None, logits=tensor([[11.1155, -7.4522, -2.7242]], grad_fn=<IndexBackward0>), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model(**inputs)\n",
    "\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "36a135da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11.1155, -7.4522, -2.7242]], grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ff29feb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutputWithPast(loss=None, logits=tensor([[11.1155, -7.4522, -2.7242]]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "08122951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000e+00, 8.6326e-09, 9.7609e-07]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn import functional\n",
    "\n",
    "probs = functional.softmax(outputs.logits, dim=-1)\n",
    "\n",
    "probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90792d0c",
   "metadata": {},
   "source": [
    "## Generación de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5690ba7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7b3a5f26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CausalLMOutputWithCrossAttentions(loss=None, logits=tensor([[[ -34.2417,  -34.3302,  -37.3032,  ...,  -43.0447,  -42.7168,\n",
       "           -35.2204],\n",
       "         [-111.0282, -111.7505, -117.2466,  ..., -119.6479, -120.1152,\n",
       "          -114.1044],\n",
       "         [ -89.3942,  -89.9615,  -92.8167,  ...,  -92.8855,  -96.1467,\n",
       "           -90.6905],\n",
       "         [-103.1975, -105.2266, -109.9585,  ..., -112.8601, -114.4420,\n",
       "          -108.3585],\n",
       "         [ -72.0004,  -73.5239,  -77.6296,  ...,  -84.3382,  -84.0815,\n",
       "           -76.9029],\n",
       "         [-109.2879, -108.5157, -110.3026,  ..., -119.1990, -118.4583,\n",
       "          -106.9128]]], grad_fn=<UnsafeViewBackward0>), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), hidden_states=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(\"Hi how are you today?\", return_tensors=\"pt\")\n",
    "\n",
    "outputs = model(**inputs)\n",
    "\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d0a3fdf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['logits', 'past_key_values'])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "183d62ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ -34.2417,  -34.3302,  -37.3032,  ...,  -43.0447,  -42.7168,\n",
       "           -35.2204],\n",
       "         [-111.0282, -111.7505, -117.2466,  ..., -119.6479, -120.1152,\n",
       "          -114.1044],\n",
       "         [ -89.3942,  -89.9615,  -92.8167,  ...,  -92.8855,  -96.1467,\n",
       "           -90.6905],\n",
       "         [-103.1975, -105.2266, -109.9585,  ..., -112.8601, -114.4420,\n",
       "          -108.3585],\n",
       "         [ -72.0004,  -73.5239,  -77.6296,  ...,  -84.3382,  -84.0815,\n",
       "           -76.9029],\n",
       "         [-109.2879, -108.5157, -110.3026,  ..., -119.1990, -118.4583,\n",
       "          -106.9128]]], grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_logits = outputs.logits\n",
    "tokens_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b4549381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[4.0598e-03, 3.7158e-03, 1.9006e-04,  ..., 6.1012e-07,\n",
       "          8.4688e-07, 1.5257e-03],\n",
       "         [5.8671e-04, 2.8493e-04, 1.1689e-06,  ..., 1.0591e-07,\n",
       "          6.6376e-08, 2.7066e-05],\n",
       "         [1.0464e-05, 5.9334e-06, 3.4145e-07,  ..., 3.1872e-07,\n",
       "          1.2222e-08, 2.8622e-06],\n",
       "         [1.2808e-03, 1.6838e-04, 1.4833e-06,  ..., 8.1486e-08,\n",
       "          1.6752e-08, 7.3469e-06],\n",
       "         [8.2389e-03, 1.7955e-03, 2.9589e-05,  ..., 3.6109e-08,\n",
       "          4.6674e-08, 6.1196e-05],\n",
       "         [1.9439e-04, 4.2073e-04, 7.0464e-05,  ..., 9.6455e-09,\n",
       "          2.0231e-08, 2.0900e-03]]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_probs = torch.softmax(tokens_logits, dim=-1)\n",
    "token_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "de8d1259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([[[0.0761, 0.0642, 0.0355, 0.0332],\n",
       "         [0.0827, 0.0694, 0.0525, 0.0509],\n",
       "         [0.6753, 0.0811, 0.0452, 0.0224],\n",
       "         [0.2560, 0.1301, 0.0952, 0.0424],\n",
       "         [0.3864, 0.1496, 0.0824, 0.0345],\n",
       "         [0.2775, 0.0697, 0.0260, 0.0241]]], grad_fn=<TopkBackward0>),\n",
       "indices=tensor([[[  13,   11,  198,   12],\n",
       "         [ 466,  881,  750,  460],\n",
       "         [ 345,  356,  484,  262],\n",
       "         [1804, 4203,   30, 1016],\n",
       "         [  30, 1701,   11,   13],\n",
       "         [ 198,  314, 1867, 1374]]]))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_top = torch.topk(token_probs, 4)\n",
    "tokens_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b492d85c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".,\n",
      "-\n",
      " do much did can\n",
      " you we they the\n",
      " doing feeling? going\n",
      "??\",.\n",
      "\n",
      " I What How\n"
     ]
    }
   ],
   "source": [
    "for indices, values in zip(tokens_top.indices, tokens_top.values):\n",
    "    for ids in indices:\n",
    "        print(tokenizer.decode(ids))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.15",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
